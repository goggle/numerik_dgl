\chapter{Finite Differenzenverfahren für die Poisson-Gleichung}


\begin{defi}
Sei $\Omega \subset \mathbb R^2$ ein \textbf{Gebiet}, d.h. eine offene, beschränkte und zusammenhängende Menge
mit Rand $\partial \Omega$, eine stückweise $C^1$-Kurve.

Für $u: \Omega \to \mathbb R$, $(x,y) \mapsto u(x,y)$, $u \in C^2(\Omega)$ heisst 
\[
\Delta u := \frac{\partial^2 u}{\partial x^2} + \frac{\partial^2 u}{\partial y^2}
\]
der \textbf{Laplace-Operator}.

Das \textbf{Poisson-Problem} mit Dirichlet-Randbedingungen lautet
\begin{align*}
- \Delta u &= f, \text{ in } \Omega \\
u &= g, \text{ auf } \partial \Omega
\end{align*}
Falls $f$ und $g$ stetig sind, sucht man $u \in C^2(\Omega) \cap C(\overline \Omega)$.
\end{defi}

\begin{bem}
\begin{enumerate}
\item Explizite Lösungsformeln existieren nur in einfachen Geometrien.
\item Andere Randbedingungen sind
\begin{itemize}
\item Neumann-Randbedingungen: $\frac{\partial u}{\partial n} = g$ auf $\partial \Omega$
\item Gemischte oder Robin-Randbedingungen: $\alpha u + \beta \frac{\partial u}{\partial n} = g$ auf $\partial \Omega$, 
$|\alpha| + |\beta| \neq 0$
\end{itemize}
\end{enumerate}
\end{bem}

\section{Finite Differenzen Diskretisierung in $\Omega = (0,1) \times (0,1)$}
Für $n \geq 1$ führe ein äquidistantes Gitter mit Maschenweite $h = \frac{1}{n+1}$ ein:
\begin{align*}
x_j &= j \cdot h, \; j = 0, \ldots, n+1 \\
y_j &= j \cdot h, \; j = 0, \ldots, n+1 \\
\Omega_h &= \{ (x_j, y_k) \ : \ 1 \leq j, k \leq n\} \\
\overline \Omega_h &= \{ (x_j, y_k) \ : \ 0 \leq j, k \leq n+1 \} \\
\partial \Omega_h &= \overline \Omega_h \setminus \Omega_h
\end{align*}

Für $u \in C^4(\Omega)$ gilt:
\begin{align*}
\frac{\partial^2 u}{\partial x^2}(x_i, y_j)
    &= \frac{1}{h^2} \left[ u(x_{i+1}, y_j) - 2u(x_i, y_j) + u(x_{i-1}, y_j) \right] + \mathcal O(h^2) \\
\frac{\partial^2 u}{\partial y^2}(x_i, y_j)
    &= \frac{1}{h^2} \left[ u(x_i, y_{j+1}) - 2u(x_i, y_j) + u(x_i, y_{j-1}) \right] + \mathcal O(h^2)
\end{align*}

Wir ersetzen das Poisson-Problem durch das diskrete Poisson-Problem:

Finde $\{u_{ij}\}_{1 \leq i, j \leq n}$ so, dass
\begin{align*}
 - \frac{1}{h^2} \left[ u_{i+1, j} + u_{i-1, j} + u_{i, j+1} + u_{i, j-1} - 4 u_{ij} \right] &= f_{ij}, \text{ für }
    (x_i, y_j) \in \Omega_h \\
 u_{ij} &= g_{ij}, \text{ für } (x_i, y_j) \in \partial \Omega_h
\end{align*}

Oder anders formuliert, finde $u_h: \overline \Omega_h \to \mathbb R$ so, dass
\begin{align*}
- \Delta_h u_h(z) &= f(z), \text{ für } z \in \Omega_h \\
u_h(z) &= g(z), \text{ für } z \in \partial \Omega_h ,
\end{align*}
wobei 
\[
( \Delta_h u_h)(x_i, y_j)
    = \frac{1}{h^2}
    \left[
    u_h(x_{i+1}, y_j) + u_h(x_{i-1}, y_j) + u_h(x_i, y_{j+1}) + u_h(x_i, y_{j-1}) - 4 u_h(x_i, y_j) 
    \right]
\]

\section{Diskretes Maximumprinzip}
Für $n \geq 1$, $h = \frac{1}{n+1}$, betrachte die Differenzengleichung
\[
L_h u_h(z) = f(x), \text{ für } z \in \Omega_h ,
\]
wobei 
\begin{align*}
L_h u_h(z) &= \sum_{z_k \in N(z)} \alpha_k (z_k) u_h(z_k), \\
N(z) &= \{ z_k \ : \ k = 0, 1, \ldots, 4 \}
\end{align*}

\begin{satz}[Diskretes Maximumsprinzip]
Sei $u_h: \overline \Omega_h \to \mathbb R$ Lösung der Differenzengleichung
\[
L_h u_h(z) = f(z), \ z \in \Omega_h
\]
mit $f(z) \leq 0$ für $z \in \Omega_h$.
Ausserdem gelte für $z \in \Omega_h$:
\begin{itemize}
\item[(i)] $ \alpha_k(z_k) < 0$ falls $1 \leq k \leq 4$
\item[(ii)] $\sum_{z_k \in N(z)} \alpha_k(z_k) = 0 $
\end{itemize}
Dann folgt
\[
\max_{z \in \Omega_h} u_h(z) \leq \max_{z \in \partial \Omega_h} u_h(z)
\]
\end{satz}
\begin{proof}
Angenommen, es gibt ein $\overline z \in \Omega_h$ mit $u_h(\overline z) = \max_{z \in \overline \Omega_h} u_h(z)$
und $u_h(\overline z) > \max_{z \in \partial \Omega_h} u_h(z)$.

Es gilt:
\begin{align*}
0 &\leq \sum_{z_k \in N(\overline z) \setminus \{ \overline z \}} \alpha_k(z_k) \left[ u_h(z_k) - u_h(\overline z) \right] \\
    &= \sum_{z_k \in N(\overline z)} \alpha_k (z_k) \left[ u_h(z_k) - u_h(\overline z) \right] \\
    &= \sum_{z_k \in N(\overline z)} \alpha_k (z_k) u_h(z_k) - u_h(\overline z) \sum_{z_k \in N(\overline z)} \alpha_k(z_k) \\
    &= L_h u_h(\overline z) - 0 = f(\overline z) \leq 0
\end{align*}
Also folgt $u_h(z_k) = u_h(\overline z)$ für $z_k \in N(\overline z)$.
Wiederhole den Beweis mit $\overline z \in N(\overline z)\setminus \{\overline z\}$, u.s.w.
Nach endlich vielen Schritten kommt man zum Rand und erhält einen Widerspruch.
\end{proof}

\begin{kor}
Seien die beiden Voraussetzungen des Satzes an $L_h$ erfüllt. Dann hat
\begin{align*}
L_h u_h( z) &= f(z), \text{ für } z \in \Omega_h \\
u_h(z) &= g(z), \text{ für } z \in \partial \Omega_h
\end{align*}
eine eindeutige Lösung.
\end{kor}
\begin{proof}
Angenommen es existieren zwei Lösungen $u_h$ und $v_h$. Dann erfüllt $w_h := u_h - v_h$
\begin{align*}
L_h w_h(z) &= 0, \text{ für } z \in \Omega_h \\
w_h(z) &= 0, \text{ für } z \in \partial \Omega_h
\end{align*}
Nach dem diskreten Maximumsprinzip folgt $w_h(z) \leq 0$ für $z \in \Omega_h$.

Ausserdem gilt:
\begin{align*}
L_h (-w_h(z)) &= 0, \text{ für } z \in \Omega_h \\
-w_h(z) &= 0, \text{ für } z \in \partial \Omega_h
\end{align*}
Also folgt wieder mit dem diskreten Maximumsprinzip $-w_h(z) \leq 0$ für $z \in \Omega_h$.
Damit ist aber $w_h = 0$ auf $\overline \Omega_h$, also $u_h = v_h$.
\end{proof}

\section{Konvergenz der Finiten Differenzen Methode}
Wir betrachten das Poisson-Problem
\begin{align*}
- \Delta u &= f \text{ in } \Omega \\
u &= g \text{ auf } \partial \Omega
\end{align*}
und das entsprechende diskrete Problem
\begin{align*}
- \Delta_h u_h &= f \text{ in } \Omega_h \\
u_h &= g \text{ auf } \partial \Omega_h
\end{align*}
und fragen uns, ob das Finite Differenzen Verfahren konvergiert, d.h. ob
\[
|u(z) - u_h(z)| \to 0 \text{ für } h \to 0
\]

\begin{defi}
Ein Finite Differenzen Verfahren $L_h$ heisst \textbf{konsistent} mit einem partiellen
Differentialoperator (2. Ordnung) $L$, falls 
\[
Lu(z) - L_h u_h(z) \to 0 \text{ für } h \to 0 \text{ und für alle } z \in \Omega_h
\]

Ein Finite Differenzenverfahren hat die \textbf{Konsistenzordnung} $m$, falls 
\[
L u(z) - L_h u_h(z) = \mathcal O(h^m) \text{ für } h \to 0
\]
und für alle $z \in \Omega_h$, $u: \Omega \to \mathbb R$ genügend oft differenzierbar.
\end{defi}

\begin{bem}
Sei $\eta_h (z) := u(z) - u_h(z)$, $z \in \Omega_h$ der Fehler.
Dann gilt für $z \in \Omega_h$:
\begin{align*}
L_h \eta_h (z)
    &= L_h (u - u_h) (z)
    = L_h u (z) - L_h u_h(z)
    = L_h u(z) - f(z) \\
    &= L_h u(z) - L u(z)
    = (L_h u - L u)(z)
    = r_h(z) ,
\end{align*}
\end{bem}
d.h. der Fehler erfüllt die Gleichung
\begin{align*}
L_h \eta_h(z) &= r_h \text{ in } \Omega_h \\
\eta_h &= 0 \text{ auf } \partial \Omega_h
\end{align*}

In Matrix-Schreibweise:
\[
A_h E_h = R_h
\]

Es gilt:
\[
\Vert E_h \Vert_\infty \leq \Vert A_h^{-1} \Vert_\infty \cdot \Vert R_h \Vert_\infty
\]

\begin{bem}
Hat $L_h$ die Konsistenzordnung $m$, so gilt:
\[
\Vert R_h \Vert_\infty = \mathcal O(h^m), \; h \to 0
\]
Damit $\Vert E_h \Vert_\infty \to 0$ für $h \to 0$ gilt, brauchen wir:
\begin{itemize}
\item \textbf{Konsistenz:} $\Vert R_h \Vert_\infty \to 0$ für $h \to 0$
\item \textbf{Stabilität:} $\Vert A_h^{-1} \Vert_\infty \leq C$ für $h \to 0$, wobei die Konstante
$C$ unabhängig von $h$ ist.
\end{itemize}
\[
\text{Konsistenz } + \text{ Stabilität } \implies \text{ Konvergenz}
\]
\end{bem}

\begin{lem}
Sei $\Omega = (0, 1) \times (0, 1)$ und $R > 0$ so, dass $\Omega \subset \mathbb B(0, R) = 
\{ (x,y) \in \mathbb R^2 : \ x^2 + y^2 \leq R^2 \}$.
Sei $v_h: \overline \Omega_h \to \mathbb R$ die Lösung von
\begin{align*}
- \Delta_h v_h &= 1 \text{ in } \Omega_h \\
v_h &= 0 \text{ auf } \partial \Omega_h
\end{align*}
Dann gilt für alle $z = (x, y) \in \overline \Omega_h$:
\[
0 \leq v_h(z) \leq \frac 1 4 \left( R^2 - \Vert z \Vert^2 \right)
\]
\end{lem}
\begin{proof}
Seien 
\begin{align*}
w(x, y) &:= \frac{ 1}{4} \left( R^2 - (x^2 + y^2) \right) \text{ für } (x,y) \in \overline \Omega \\
w_h(x_i, y_j) &:= w(x_i, y_j) \text{ für } (x_i, y_j) \in \overline \Omega_h .
\end{align*}
Es ist
\begin{align*}
- \Delta w(x,y) &= - \left( \frac{ \partial^2}{\partial x^2} + \frac{\partial^2}{\partial y^2} \right)
    \cdot \frac 1 4 \left( R^2 - (x^2 + y^2) \right) \\
    &= \frac{\partial }{\partial x} \left( \frac 1 2 x \right) + \frac{\partial }{\partial y}
    \left( \frac 1 2 y \right)
    = \frac 1 2 + \frac 1 2 = 1
\end{align*}
Unter Verwendung des Fünf-Punkte-Sterns, rechnet man nach, dass auch
\[
- \Delta_h w_h = 1
\]
gilt.
Da $w_h | \partial \Omega_h = \frac 1 4 \left( R^2 - (x^2 + y^2) \right) \geq 0$, erhalten wir
\begin{align*}
- \Delta_h (v_h - w_h) &= 0 \text{ in } \Omega_h \\
v_h - w_h &\leq 0 \text{ auf } \partial \Omega_h
\end{align*}
Das Maximumsprinzip liefert nun
\[
v_h(z) - w_h(z) \leq 0 \text{ für } z \in \partial \Omega_h .
\]
Ausserdem gilt
\begin{align*}
- \Delta_h (-v_h) &= -1 \text{ in } \Omega_h \\
-v_h &= 0 \text{ auf } \partial \Omega_h
\end{align*}
Also ist nach dem Maximumsprinzip
\[
v_h(z) \leq 0 \text{ für } z \in \Omega_h
\]
Insgesamt haben wir also
\[
0 \leq v_h(z) \leq w_h(z) \text{ für } z \in \overline \Omega_h
\]
\end{proof}

\begin{satz}[Konvergenz]
Seien $\Omega = (0,1) \times (0,1)$ und $u: \Omega \to \mathbb R$, $u_h: \Omega_h \to \mathbb R$
Lösungen von
\begin{align*}
- \Delta u &= f \text{ in } \Omega \\
u &= g \text{ auf } \partial \Omega
\end{align*}
und
\begin{align*}
- \Delta_h u_h &= f \text{ in } \Omega_h \\
u_h &= g \text{ auf } \partial \Omega_h
\end{align*}

Dann gilt:
\begin{align*}
\Vert u - u_h \Vert_\infty &\leq Ch^2, \; h \to 0, \; u \in C^4( \overline \Omega) \\
\Vert u - u_h \Vert_\infty &\leq Ch, \; h \to 0, \; u \in C^3( \overline \Omega) \\
\Vert u - u_h \Vert_\infty &\to 0, \; h \to 0, \; u \in C^2( \overline \Omega)
\end{align*}
\end{satz}

\begin{proof}
Sei $\eta_h(z) := u(z) - u_h(z)$, $z \in \overline \Omega_h$ der Fehler.

Wir wissen:
\begin{align*}
- \Delta_h \eta_h &= r_h := \Delta u - \Delta_h u \text{ in } \Omega_h \\
\eta_h &= 0 \text{ auf } \partial \Omega_h
\end{align*}

Weiter gilt (siehe Serie 3):
\begin{align*}
\Vert r_h \Vert_\infty &\leq Ch^2, \; h \to 0, \; u \in C^4( \overline \Omega) \\
\Vert r_h \Vert_\infty &\leq Ch, \; h \to 0, \; u \in C^3( \overline \Omega) \\
\Vert r_h \Vert_\infty &\to 0, \; h \to 0, \; u \in C^2( \overline \Omega) \\
\end{align*}

Wir müssen die Stabilität beweisen, d.h. $\Vert \eta_h \Vert_\infty \leq C \Vert r_h \Vert_\infty$.
Dazu betrachten wir
\begin{align*}
- \Delta_h v_h &= 1 \text{ in } \Omega_h \\
v_h &= 0 \text{ auf } \partial \Omega_h 
\end{align*}

Es folgt:
\begin{align*}
- \Delta_h \left( \pm \eta_h - \Vert r_h \Vert_\infty v_h \right) = \left( \pm r_h - \Vert r_h \Vert_\infty
 \right) &\leq 0 \text{ in } \Omega_h \\
 \pm \eta_h - \Vert r_h \Vert_\infty v_h &= 0 \text{ auf } \partial \Omega_h
\end{align*}

Das Maximumsprinzip impliziert nun
\[
\pm \eta_h - \Vert r_h \Vert_\infty v_h \leq 0 \text{ in } \overline \Omega_h .
\]
Also ist auch 
\[
| \eta_h (z) | \leq \Vert r_h \Vert_\infty | v_h (z) |
\]
für $z \in \overline \Omega_h$.

Nun folgt mit dem Lemma:
\[
\Vert \eta_h \Vert_\infty \leq \Vert r_h \Vert_\infty \Vert v_h \Vert_\infty
    \leq \Vert r_h \Vert_\infty \cdot \frac 1 4 R^2
\]
\end{proof}

\begin{bem}
\begin{enumerate}
\item Der obige Beweis gilt auch für allgemeine Gebiete, die diskret zusammenhängend sind. Der Beweis
des Maximumsprinzip und des Lemmas sind identisch.
\item Finite Differenzen Verfahren sind extrem effizient auf regelmässigen Gittern und einfachen 
Geometrien. Sie lassen sich allerdings nur schwer anwenden bei
\begin{itemize}
\item Krummen Rändern
\item Unstrukturierten Gittern
\item Lokalen Verfeinerungen
\end{itemize}
\item Verahren höherer Ordnung benutzen mehr Punkte, z.B. der Neun-Punkte-Stern. Dies wiederum führt zu
Problemen bei Randbedingungen.
\end{enumerate}
\end{bem}






